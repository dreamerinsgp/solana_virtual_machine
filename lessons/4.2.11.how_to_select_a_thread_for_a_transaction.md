Q1: how to select a thread for a transaction?

**Answer:**

Thread selection for a transaction is a **multi-step filtering process** that narrows down candidate threads based on account lock constraints and capacity limits, then selects the **least loaded thread** using load balancing metrics.

**Location:** `agave_v1/core/src/banking_stage/transaction_scheduler/`

## Overview: Multi-Step Filtering Process

Thread selection follows this pipeline:

```
All threads
    ↓
Step 1: Filter by account locks (which threads can access all accounts?)
    ↓
Step 2: Filter by capacity constraints (which threads are below capacity?)
    ↓
Step 3: Intersect the two sets (threads that satisfy both)
    ↓
Step 4: Select least loaded thread (load balancing)
    ↓
Selected thread
```

## Step-by-Step Process

### **Step 1: Determine Schedulable Threads from Account Locks**

**Location:** `agave_v1/scheduling-utils/src/thread_aware_account_locks.rs:96-98`

**Purpose:** Find which threads can access **all** accounts the transaction needs.

```rust
// From thread_aware_account_locks.rs:96-98
let schedulable_threads = self
    .accounts_schedulable_threads(write_account_locks.clone(), read_account_locks.clone())
    .ok_or(TryLockError::MultipleConflicts)?;
```

**How it works:**
```rust
// From thread_aware_account_locks.rs:126-148
fn accounts_schedulable_threads<'a>(
    &self,
    write_account_locks: impl Iterator<Item = &'a Pubkey>,
    read_account_locks: impl Iterator<Item = &'a Pubkey>,
) -> Option<ThreadSet> {
    let mut schedulable_threads = ThreadSet::any(self.num_threads);  // Start with all threads
    
    // For each write account: intersect with threads that can write it
    for account in write_account_locks {
        schedulable_threads &= self.write_schedulable_threads(account);
        if schedulable_threads.is_empty() {
            return None;  // No threads can access all accounts
        }
    }
    
    // For each read account: intersect with threads that can read it
    for account in read_account_locks {
        schedulable_threads &= self.read_schedulable_threads(account);
        if schedulable_threads.is_empty() {
            return None;  // No threads can access all accounts
        }
    }
    
    Some(schedulable_threads)
}
```

**Account Lock Rules:**
- **Unlocked account**: Any thread can access
- **Write-locked by Thread X**: Only Thread X can access
- **Read-locked by Threads {X, Y}**: Any thread can read, but only Threads {X, Y} can write (if single thread holds all reads)

**Example:**
```
Transaction needs: Account A (write), Account B (read)

Account A: Write-locked by Thread 2 → Only Thread 2
Account B: Read-locked by Threads {1, 3} → Any thread (for reads)

Schedulable threads: Thread 2 (intersection)
```

### **Step 2: Apply Capacity Constraints**

**Location:** `agave_v1/core/src/banking_stage/transaction_scheduler/prio_graph_scheduler.rs:133-140`

**Purpose:** Remove threads that are at or above capacity.






Q2: **What is Capacity?**

Capacity is the **maximum amount of computational work** (measured in **compute units**) that a thread can handle at one time. It prevents threads from being overloaded with too much work.

**Capacity Calculation:**
```rust
// From prio_graph_scheduler.rs:131
let max_cu_per_thread = self.config.max_scheduled_cus / num_threads as u64;
```

**Components:**
- **`max_scheduled_cus`**: Maximum total compute units that can be scheduled across all threads (e.g., `MAX_BLOCK_UNITS`)
- **`num_threads`**: Number of worker threads
- **`max_cu_per_thread`**: Maximum compute units per thread (distributed evenly)

**Example:**
```
max_scheduled_cus = 1,200,000 (total capacity)
num_threads = 4

max_cu_per_thread = 1,200,000 / 4 = 300,000 CUs per thread
```

**What is "In-Flight" Compute Units?**

**In-flight compute units** (`in_flight_cus_per_thread`) are the compute units of transactions **currently executing** on a thread. These are tracked by the `InFlightTracker`.

**How it works:**
- When a batch is **sent** to a thread for execution, its compute units are added to `in_flight_cus_per_thread[thread_id]`
- When a batch **completes**, its compute units are subtracted from `in_flight_cus_per_thread[thread_id]`

**Capacity Check:**
```rust
// From prio_graph_scheduler.rs:135-137
if self.common.in_flight_tracker.cus_in_flight_per_thread()[thread_id]
    >= max_cu_per_thread
{
    schedulable_threads.remove(thread_id);  // Thread is at capacity
}
```

**A thread is "at capacity" when:**
- `in_flight_cus_per_thread[thread_id] >= max_cu_per_thread`
- The thread is **already executing** enough work and cannot accept more
- New transactions cannot be scheduled on this thread until some work completes

```rust
// From prio_graph_scheduler.rs:133-140
let mut schedulable_threads = ThreadSet::any(num_threads);
for thread_id in 0..num_threads {
    if self.common.in_flight_tracker.cus_in_flight_per_thread()[thread_id]
        >= max_cu_per_thread
    {
        schedulable_threads.remove(thread_id);  // Remove overloaded threads
    }
}
```

**Capacity Calculation:**
```rust
let max_cu_per_thread = self.config.max_scheduled_cus / num_threads as u64;
```

**What it checks:**
- **In-flight compute units** per thread
- If `in_flight_cus >= max_cu_per_thread`, thread is **at capacity**
- At-capacity threads are **removed** from the schedulable set

**Example:**
```
max_cu_per_thread = 1000

Thread 0: in_flight_cus = 800  → Below capacity ✅
Thread 1: in_flight_cus = 1000 → At capacity ❌ (removed)
Thread 2: in_flight_cus = 1200 → Above capacity ❌ (removed)
Thread 3: in_flight_cus = 500  → Below capacity ✅

Allowed threads after capacity filter: {0, 3}
```

### **Step 3: Intersect Account-Lock and Capacity Sets**

**Location:** `agave_v1/scheduling-utils/src/thread_aware_account_locks.rs:99`

**Purpose:** Find threads that satisfy **both** account lock constraints and capacity limits.

```rust
// From thread_aware_account_locks.rs:99
let schedulable_threads = schedulable_threads & allowed_threads;
if schedulable_threads.is_empty() {
    return Err(TryLockError::ThreadNotAllowed);
}
```

**How it works:**
- **Account-lock schedulable threads**: Threads that can access all accounts
- **Capacity-allowed threads**: Threads below capacity
- **Intersection**: Only threads in **both** sets remain

**Example:**
```
Account-lock schedulable: {Thread 1, Thread 2}
Capacity-allowed: {Thread 0, Thread 2, Thread 3}

Intersection: {Thread 2}  (only thread in both sets)
```

**If intersection is empty:**
- Transaction becomes **unschedulable** (`ThreadNotAllowed`)
- Must wait until capacity clears or locks are released

### **Step 4: Select Least Loaded Thread (Load Balancing)**

**Location:** `agave_v1/core/src/banking_stage/transaction_scheduler/scheduler_common.rs:125-144`

**Purpose:** From the schedulable threads, select the **least loaded** one.

```rust
// From scheduler_common.rs:125-144
pub fn select_thread<Tx>(
    thread_set: ThreadSet,  // Schedulable threads (after filtering)
    batch_cus_per_thread: &[u64],  // Compute units in batches (not yet sent)
    in_flight_cus_per_thread: &[u64],  // Compute units executing
    batches_per_thread: &[Vec<Tx>],  // Transactions in batches
    in_flight_per_thread: &[usize],  // Transactions executing
) -> ThreadId {
    thread_set
        .contained_threads_iter()
        .map(|thread_id| {
            (
                thread_id,
                // Total compute units (batch + in-flight)
                batch_cus_per_thread[thread_id] + in_flight_cus_per_thread[thread_id],
                // Total transaction count (batch + in-flight)
                batches_per_thread[thread_id].len() + in_flight_per_thread[thread_id],
            )
        })
        // Select thread with minimum compute units, then minimum transaction count
        .min_by(|a, b| a.1.cmp(&b.1).then_with(|| a.2.cmp(&b.2)))
        .map(|(thread_id, _, _)| thread_id)
        .unwrap()
}
```

**Selection Criteria:**

1. **Primary**: Minimum **total compute units**
   - `total_cus = batch_cus + in_flight_cus`
   - Prefers threads with less computational load

2. **Secondary**: Minimum **total transaction count** (if compute units are equal)
   - `total_txs = batch_txs.len() + in_flight_txs`
   - Breaks ties by preferring threads with fewer transactions

**Example:**
```
Schedulable threads: {Thread 1, Thread 2, Thread 3}

Thread 1:
  batch_cus = 200, in_flight_cus = 300 → total_cus = 500
  batch_txs = 5, in_flight_txs = 3 → total_txs = 8

Thread 2:
  batch_cus = 100, in_flight_cus = 200 → total_cus = 300
  batch_txs = 3, in_flight_txs = 2 → total_txs = 5

Thread 3:
  batch_cus = 150, in_flight_cus = 150 → total_cus = 300
  batch_txs = 2, in_flight_txs = 1 → total_txs = 3

Selection:
  - Thread 2 and Thread 3 tie on total_cus (300)
  - Thread 3 wins on total_txs (3 < 5)
  → Selected: Thread 3
```

## Complete Flow in Code

### **Entry Point: `try_schedule_transaction()`**

**Location:** `agave_v1/core/src/banking_stage/transaction_scheduler/prio_graph_scheduler.rs:241-256`

```rust
let maybe_schedule_info = try_schedule_transaction(
    transaction_state,
    &pre_lock_filter,
    &mut blocking_locks,
    &mut self.common.account_locks,
    num_threads,
    |thread_set| {  // thread_selector closure
        select_thread(
            thread_set,  // Schedulable threads from account locks
            self.common.batches.total_cus(),  // Batch compute units
            self.common.in_flight_tracker.cus_in_flight_per_thread(),  // In-flight CUs
            self.common.batches.transactions(),  // Batch transactions
            self.common.in_flight_tracker.num_in_flight_per_thread(),  // In-flight txs
        )
    },
);
```

### **Inside `try_lock_accounts()`**

**Location:** `agave_v1/scheduling-utils/src/thread_aware_account_locks.rs:89-107`

```rust
pub fn try_lock_accounts<'a>(
    &mut self,
    write_account_locks: impl Iterator<Item = &'a Pubkey>,
    read_account_locks: impl Iterator<Item = &'a Pubkey>,
    allowed_threads: ThreadSet,  // Capacity-filtered threads
    thread_selector: impl FnOnce(ThreadSet) -> ThreadId,  // select_thread function
) -> Result<ThreadId, TryLockError> {
    // Step 1: Find threads that can schedule all accounts
    let schedulable_threads = self
        .accounts_schedulable_threads(write_account_locks.clone(), read_account_locks.clone())
        .ok_or(TryLockError::MultipleConflicts)?;
    
    // Step 2: Intersect with capacity-allowed threads
    let schedulable_threads = schedulable_threads & allowed_threads;
    if schedulable_threads.is_empty() {
        return Err(TryLockError::ThreadNotAllowed);
    }

    // Step 3: Select best thread using load balancing
    let thread_id = thread_selector(schedulable_threads);
    
    // Step 4: Lock accounts on selected thread
    self.lock_accounts(write_account_locks, read_account_locks, thread_id);
    Ok(thread_id)
}
```

## Examples: Thread Selection in Action

### **Example 1: Single Thread Available (No Choice)**

**Transaction needs:** Account X (write)

**State:**
- Account X: Write-locked by Thread 2
- Thread 2: Below capacity

**Selection Process:**
1. Account-lock schedulable: {Thread 2} (only thread with Account X)
2. Capacity-allowed: {Thread 0, Thread 1, Thread 2, Thread 3}
3. Intersection: {Thread 2}
4. Load balancing: Only one thread → **Thread 2 selected**

**Result:** Thread 2 (no choice, but still locks accounts)

### **Example 2: Multiple Threads Available (Load Balancing)**

**Transaction needs:** Account Y (read)

**State:**
- Account Y: Read-locked by Threads {1, 3} (any thread can read)
- All threads: Below capacity

**Selection Process:**
1. Account-lock schedulable: {Thread 0, Thread 1, Thread 2, Thread 3} (any thread can read)
2. Capacity-allowed: {Thread 0, Thread 1, Thread 2, Thread 3}
3. Intersection: {Thread 0, Thread 1, Thread 2, Thread 3}
4. Load balancing:
   ```
   Thread 0: total_cus = 500, total_txs = 10
   Thread 1: total_cus = 300, total_txs = 8
   Thread 2: total_cus = 300, total_txs = 5
   Thread 3: total_cus = 400, total_txs = 7
   
   Minimum total_cus: Thread 1, Thread 2 (tie at 300)
   Minimum total_txs: Thread 2 (5 < 8)
   ```
   → **Thread 2 selected**

**Result:** Thread 2 (least loaded among all threads)

### **Example 3: Capacity Constraint**

**Transaction needs:** Account Z (write)

**State:**
- Account Z: Write-locked by Thread 1
- Thread 1: At capacity (in_flight_cus >= max_cu_per_thread)
- Other threads: Below capacity, but don't have Account Z

**Selection Process:**
1. Account-lock schedulable: {Thread 1} (only thread with Account Z)
2. Capacity-allowed: {Thread 0, Thread 2, Thread 3} (Thread 1 removed)
3. Intersection: {} (empty!)
4. Result: **`ThreadNotAllowed` error**

**Result:** Transaction becomes **unschedulable**, must wait until Thread 1 completes work

### **Example 4: Cross-Account Constraint**

**Transaction needs:** Account A (write), Account B (read)

**State:**
- Account A: Write-locked by Thread 2
- Account B: Read-locked by Threads {1, 3} (any thread can read)
- All threads: Below capacity

**Selection Process:**
1. Account-lock schedulable:
   - Account A: {Thread 2}
   - Account B: {Thread 0, Thread 1, Thread 2, Thread 3}
   - Intersection: {Thread 2} (must access both accounts)
2. Capacity-allowed: {Thread 0, Thread 1, Thread 2, Thread 3}
3. Intersection: {Thread 2}
4. Load balancing: Only one thread → **Thread 2 selected**

**Result:** Thread 2 (only thread that can access both accounts)

## Key Metrics Used for Load Balancing

### **1. Compute Units (Primary Criterion)**

**What it measures:** Total computational load on a thread

**Components:**
- **Batch CUs**: Compute units in transactions waiting to be sent
- **In-flight CUs**: Compute units in transactions currently executing

**Formula:**
```
total_cus = batch_cus_per_thread[thread_id] + in_flight_cus_per_thread[thread_id]
```

**Why it matters:** Prefers threads with less computational load, preventing overload

### **2. Transaction Count (Secondary Criterion)**

**What it measures:** Total number of transactions on a thread

**Components:**
- **Batch transactions**: Transactions in batches waiting to be sent
- **In-flight transactions**: Transactions currently executing

**Formula:**
```
total_txs = batches_per_thread[thread_id].len() + in_flight_per_thread[thread_id]
```

**Why it matters:** Breaks ties when compute units are equal, prefers threads with fewer transactions

## Summary: Thread Selection Process

| Step | Purpose | Method | Result |
|------|---------|--------|--------|
| **1. Account Lock Filter** | Find threads that can access all accounts | Intersect schedulable threads for each account | Set of threads that can access all accounts |
| **2. Capacity Filter** | Remove threads at capacity | Check `in_flight_cus >= max_cu_per_thread` | Set of threads below capacity |
| **3. Intersection** | Find threads satisfying both constraints | Bitwise AND of two sets | Final candidate threads |
| **4. Load Balancing** | Select least loaded thread | `min_by(total_cus, total_txs)` | Selected thread ID |

**Selection Criteria:**
1. **Primary**: Minimum total compute units (batch + in-flight)
2. **Secondary**: Minimum total transaction count (if compute units equal)

**Key Points:**

1. **Account locks determine feasibility**: Only threads that can access all accounts are considered
2. **Capacity prevents overload**: Threads at capacity are excluded
3. **Load balancing optimizes distribution**: Least loaded thread is selected
4. **Multiple constraints**: All constraints must be satisfied (AND logic)
5. **Failures**: If no threads satisfy constraints, transaction becomes unschedulable

The thread selection process ensures transactions are assigned to threads that can access their accounts, are below capacity, and are least loaded, maximizing parallelism while preventing overload and conflicts.



Q3: define least loaded (load balancing)?

**Answer:**

"Least loaded" refers to the thread with the **minimum total workload** among all schedulable threads. Load balancing ensures work is **distributed evenly** across threads by selecting the thread with the smallest current load.

**Location:** `agave_v1/core/src/banking_stage/transaction_scheduler/scheduler_common.rs:125-144`

## What Does "Least Loaded" Mean?

A thread's **load** is measured by two metrics:

1. **Total Compute Units** (primary criterion)
   - Sum of compute units in batches waiting to be sent + compute units currently executing
   - Represents the **computational work** the thread is handling

2. **Total Transaction Count** (secondary criterion)
   - Number of transactions in batches + number of transactions currently executing
   - Represents the **number of tasks** the thread is handling

**Formula:**
```rust
// From scheduler_common.rs:137-138
total_cus = batch_cus_per_thread[thread_id] + in_flight_cus_per_thread[thread_id]
total_txs = batches_per_thread[thread_id].len() + in_flight_per_thread[thread_id]
```

## How Load Balancing Works

### **Selection Algorithm**

```rust
// From scheduler_common.rs:132-143
thread_set
    .contained_threads_iter()
    .map(|thread_id| {
        (
            thread_id,
            batch_cus_per_thread[thread_id] + in_flight_cus_per_thread[thread_id],  // total_cus
            batches_per_thread[thread_id].len() + in_flight_per_thread[thread_id],  // total_txs
        )
    })
    // Select thread with minimum compute units, then minimum transaction count
    .min_by(|a, b| a.1.cmp(&b.1).then_with(|| a.2.cmp(&b.2)))
    .map(|(thread_id, _, _)| thread_id)
    .unwrap()
```

**Selection Process:**
1. **Calculate load** for each schedulable thread (total_cus, total_txs)
2. **Compare by primary criterion**: Select thread with **minimum total_cus**
3. **Break ties**: If total_cus are equal, select thread with **minimum total_txs**
4. **Return**: The thread ID of the least loaded thread

### **Selection Criteria Priority**

| Priority | Criterion | What It Measures | Why It Matters |
|----------|-----------|------------------|----------------|
| **1st** | Minimum total compute units | Computational workload | Prevents computational overload |
| **2nd** | Minimum total transaction count | Number of tasks | Breaks ties, prefers fewer tasks |

## Components of Load

### **1. Batch Compute Units (`batch_cus_per_thread`)**

**What it is:** Compute units in transactions that are **scheduled but not yet sent** to the thread for execution.

**When it's added:** When transactions are added to batches via `add_transaction_to_batch()`

**When it's cleared:** When batches are sent to threads via `send_batch()`

**Example:**
```
Thread 2 has a batch with 3 transactions:
  Transaction A: 100 CUs
  Transaction B: 150 CUs
  Transaction C: 200 CUs
  
batch_cus_per_thread[2] = 450 CUs
```

### **2. In-Flight Compute Units (`in_flight_cus_per_thread`)**

**What it is:** Compute units in transactions **currently executing** on the thread.

**When it's added:** When a batch is sent to the thread for execution (`track_batch()`)

**When it's cleared:** When a batch completes execution (`complete_batch()`)

**Example:**
```
Thread 2 is executing a batch:
  Transaction D: 300 CUs (executing)
  Transaction E: 250 CUs (executing)
  
in_flight_cus_per_thread[2] = 550 CUs
```

### **3. Batch Transaction Count (`batches_per_thread[thread_id].len()`)**

**What it is:** Number of transactions in batches **waiting to be sent**.

**Example:**
```
Thread 2 has a batch with 3 transactions:
  batches_per_thread[2].len() = 3
```

### **4. In-Flight Transaction Count (`in_flight_per_thread[thread_id]`)**

**What it is:** Number of transactions **currently executing** on the thread.

**Example:**
```
Thread 2 is executing a batch with 2 transactions:
  in_flight_per_thread[2] = 2
```

## Examples: Load Balancing in Action

### **Example 1: Clear Winner (Different Compute Units)**

**Schedulable threads:** {Thread 0, Thread 1, Thread 2}

**Load calculation:**
```
Thread 0:
  batch_cus = 200, in_flight_cus = 300 → total_cus = 500
  batch_txs = 5, in_flight_txs = 3 → total_txs = 8

Thread 1:
  batch_cus = 100, in_flight_cus = 200 → total_cus = 300
  batch_txs = 3, in_flight_txs = 2 → total_txs = 5

Thread 2:
  batch_cus = 150, in_flight_cus = 250 → total_cus = 400
  batch_txs = 4, in_flight_txs = 2 → total_txs = 6
```

**Selection:**
- Minimum total_cus: Thread 1 (300)
- **Selected: Thread 1** (clearly least loaded)

### **Example 2: Tie-Breaking (Equal Compute Units)**

**Schedulable threads:** {Thread 1, Thread 2}

**Load calculation:**
```
Thread 1:
  batch_cus = 100, in_flight_cus = 200 → total_cus = 300
  batch_txs = 5, in_flight_txs = 3 → total_txs = 8

Thread 2:
  batch_cus = 150, in_flight_cus = 150 → total_cus = 300  (tie!)
  batch_txs = 2, in_flight_txs = 1 → total_txs = 3
```

**Selection:**
- Minimum total_cus: Thread 1, Thread 2 (both 300) → **tie**
- Minimum total_txs: Thread 2 (3 < 8)
- **Selected: Thread 2** (tie broken by transaction count)

### **Example 3: Single Thread (No Choice)**

**Schedulable threads:** {Thread 2} (only thread that can access required accounts)

**Load calculation:**
```
Thread 2:
  batch_cus = 500, in_flight_cus = 300 → total_cus = 800
  batch_txs = 10, in_flight_txs = 5 → total_txs = 15
```

**Selection:**
- Only one thread available → **Thread 2 selected** (no load balancing needed)

## Why Load Balancing Matters

### **1. Prevents Overload**

**Without load balancing:**
```
All transactions assigned to Thread 0:
  Thread 0: total_cus = 10,000 (overloaded!)
  Thread 1: total_cus = 0 (idle)
  Thread 2: total_cus = 0 (idle)
  Thread 3: total_cus = 0 (idle)
```

**With load balancing:**
```
Work distributed evenly:
  Thread 0: total_cus = 2,500
  Thread 1: total_cus = 2,500
  Thread 2: total_cus = 2,500
  Thread 3: total_cus = 2,500
```

### **2. Maximizes Throughput**

**Benefit:** Even distribution ensures all threads are utilized, maximizing overall system throughput.

**Example:**
```
Without load balancing: 1 thread working at 100%, 3 threads idle → 25% utilization
With load balancing: 4 threads working at 100% → 100% utilization
```

### **3. Reduces Latency**

**Benefit:** Work is distributed across threads, so transactions don't wait in long queues on overloaded threads.

**Example:**
```
Thread 0: 100 transactions queued (long wait time)
Thread 1: 5 transactions queued (short wait time)

Load balancing assigns new transactions to Thread 1 → faster execution
```

### **4. Improves Resource Utilization**

**Benefit:** All CPU cores are utilized efficiently, preventing some threads from being idle while others are overloaded.

## Load Balancing vs Capacity

**Key Difference:**

| Aspect | Capacity | Load Balancing |
|--------|----------|----------------|
| **Purpose** | Prevent overload (hard limit) | Optimize distribution (soft optimization) |
| **Metric** | Only in-flight CUs | Total CUs (batch + in-flight) |
| **Action** | Remove threads from schedulable set | Select best thread from schedulable set |
| **When applied** | Before thread selection | During thread selection |

**Relationship:**
1. **Capacity filter** removes threads that are **at or above capacity** (hard limit)
2. **Load balancing** selects the **least loaded** thread from remaining schedulable threads (optimization)

**Example:**
```
Step 1: Capacity filter
  Thread 0: in_flight_cus = 800 (below capacity) ✅
  Thread 1: in_flight_cus = 1000 (at capacity) ❌ removed
  Thread 2: in_flight_cus = 600 (below capacity) ✅
  
Step 2: Load balancing (from remaining threads)
  Thread 0: total_cus = 800 + 200 = 1000
  Thread 2: total_cus = 600 + 100 = 700
  
  Selected: Thread 2 (least loaded)
```

## Summary: Least Loaded Definition

**"Least loaded"** means the thread with:
- **Minimum total compute units** (primary criterion)
  - `total_cus = batch_cus + in_flight_cus`
- **Minimum total transaction count** (secondary criterion, breaks ties)
  - `total_txs = batch_txs.len() + in_flight_txs`

**Load Balancing Benefits:**
1. ✅ **Prevents overload** - Distributes work evenly
2. ✅ **Maximizes throughput** - Utilizes all threads
3. ✅ **Reduces latency** - Avoids long queues
4. ✅ **Improves resource utilization** - Efficient CPU usage

**Key Insight:** Load balancing ensures work is distributed **evenly** across threads, preventing some threads from being overloaded while others remain idle. This maximizes parallelism and system efficiency.
